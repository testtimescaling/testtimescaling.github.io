<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="figs/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>What, How, Where, and How Well? A Survey on Test-Time Scaling in Large Language Models</title>
  
  <!-- ======== 2. å­—ä½“/æ ·å¼/ä¾èµ–æ–‡ä»¶è·¯å¾„ ======== -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <!-- ======== <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css"> ======== -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@latest/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma-carousel@4.0.4/dist/css/bulma-carousel.min.css">
  <link rel="stylesheet" href=".css/bulma-slider.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href=".css/index.css">

</head>
<body>




                  <section class="hero">
                    <div class="hero-body">
                      <div class="container is-max-desktop">
                        <div class="columns is-centered">
                          <div class="column has-text-centered">
                            <h1 class="title is-1 publication-title"> What, How, Where, and How Well? A Survey on Test-Time Scaling in Large Language Models</h1>
                            <div class="is-size-5 publication-authors">
                              <!-- Paper authors -->
                              <span class="author-block">
                                  <a href="#" target="_blank">Qiyuan Zhang</a><sup>+</sup>,</span>
                              <span class="author-block">
                                  <a href="#" target="_blank">Fuyuan Lyu</a><sup>*</sup>,</span>
                              <span class="author-block">
                                  <a href="#" target="_blank">Zexu Sun</a><sup>â€¡</sup>,</span>
                              <span class="author-block">
                                  <a href="#" target="_blank">Lei Wang</a><sup>Â¶</sup>,</span>
                              <span class="author-block">
                                  <a href="#" target="_blank">Weixu Zhang</a><sup>*</sup>,</span>  <!-- è¡¥å……é“¾æ¥ -->
                              <span class="author-block">
			         <a href="#" target="_blank">Wenyue Hua</a><sup>â˜†</sup>,</span>  <!-- è¡¥å……é“¾æ¥ -->
                              <span class="author-block">
				<a href="#" target="_blank">Haolun Wu</a><sup>â˜…</sup>,</span>  <!-- è¡¥å……é“¾æ¥ -->
                              <span class="author-block">
                                  <a href="#" target="_blank">Zhihan Guo</a><sup>Â§</sup>,</span>    <!-- è¡¥å……é“¾æ¥ -->
                              <span class="author-block">
                                  <a href="#" target="_blank">Yufei Wang</a><sup>â€–</sup>,</span> <!-- æ›¿æ¢ # -->
                              <span class="author-block">
                                  <a href="#" target="_blank">Niklas Muennighoff</a><sup>â˜…</sup>,</span>   <!-- æ›¿æ¢ & -->
                              <span class="author-block">
                                  <a href="#" target="_blank">Irwin King</a><sup>Â§</sup></span>
			      <span class="author-block">
                                  <a href="#" target="_blank">Xue Liu</a><sup>*</sup></span>
                              <span class="author-block">
                                  <a href="#" target="_blank">Chen Ma</a><sup>+</sup></span>
                          </div>
                          
                          <div class="is-size-5 publication-authors">
                              <span class="author-block">City University of Hong Kong<sup>+</sup>,</span>
                              <span class="author-block">McGill University & MILA<sup>*</sup>,</span>
                              <span class="author-block">Gaoling School of Artificial Intelligence, Renmin University of China<sup>â€¡</sup>,</span> <!-- æ›¿æ¢ # -->
                              <span class="author-block">Chinese University of Hong Kong<sup>Â§</sup></span>          <!-- æ›¿æ¢ & -->
			      <span class="author-block">Salesforce AI Research<sup>Â¶</sup></span>
			      <span class="author-block">Macquarie University<sup>â€–</sup></span>
			      <span class="author-block">Stanford University<sup>â˜…</sup></span>
			      <span class="author-block">University of California, Santa Barbara<sup>â˜†</sup></span>
                          </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2503.24235" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/testtimescaling/testtimescaling.github.io" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2503.24235" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

	      <span class="link-block">
		  <a href="https://github.com/zhangqiyuan-rico/zhangqiyuan-rico.github.io/tree/main/TTS" target="_blank"
		     class="external-link button is-normal is-rounded is-danger">
		    <span class="icon">
		      <i class="fas fa-file-powerpoint"></i>
		    </span>
		    <span>PPT</span>
		  </a>
		</span>
            </div>
		<!-- åœ¨é“¾æ¥åŒºä¸‹é¢æ’å…¥å›¾ç‰‡ -->
	  <div style="margin-top: 3rem;">
	    <img src="figs/goku_all.png" alt="Goku All" style="max-width: 800px;">
	  </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        Your video here
        <source src="videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            As enthusiasm for scaling computation (data and parameters) in the pretraining era gradually diminished, test-time scaling (TTS), also referred to as ``test-time computing'' has emerged as a prominent research focus. Recent studies demonstrate that TTS can further elicit the problem-solving capabilities of large language models (LLMs), enabling significant breakthroughs not only in specialized reasoning tasks, such as mathematics and coding, but also in general tasks like open-ended Q&A. However, despite the explosion of recent efforts in this area, there remains an urgent need for a comprehensive survey offering a systemic understanding. To fill this gap, we propose a unified, multidimensional framework structured along four core dimensions of TTS research: what to scale, how to scale, where to scale, and how well to scale. Building upon this taxonomy, we conduct an extensive review of methods, application scenarios, and assessment aspects, and present an organized decomposition that highlights the unique functional roles of individual techniques within the broader TTS landscape. From this analysis, we distill the major developmental trajectories of TTS to date and offer hands-on guidelines for practical deployment. Furthermore, we identify several open challenges and offer insights into promising future directions, including further scaling, clarifying the functional essence of techniques, generalizing to more tasks, and more attributions.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      
      <div id="results-carousel"
     class="carousel results-carousel"
     style="overflow: hidden;">
        
        <!-- è½®æ’­é¡¹1 -->
        <div class="item">
          <figure class="image-container">
            <img src="figs/TTS-intro.png" alt="TTS Intro"/>
            <figcaption class="subtitle is-6">Figure 1: Comparison of Scaling Paradigms in Pre-training and Test-time Phases.</figcaption>
          </figure>
        </div>
        
        <!-- è½®æ’­é¡¹2 -->
        <div class="item">
          <figure class="image-container">
            <img src="figs/TTS-how.png" alt="TTS How"/>
            <figcaption class="subtitle is-6">Figure 2: A Visual Map and Comparison: From What to Scale to How to Scale.</figcaption>
          </figure>
        </div>
        
        <!-- è½®æ’­é¡¹3 -->
        <div class="item">
          <figure class="image-container">
            <img src="figs/taxonomy.png" alt="TTS Taxonomy"/>
            <figcaption class="subtitle is-6">Figure 3: Taxonomy of research in Test-time Scaling.</figcaption>
          </figure>
        </div>

	<!-- è½®æ’­é¡¹4 -->
        <div class="item">
          <figure class="image-container">
            <img src="figs/summary_stimulation.png" alt="TTS stimulation"/>
            <figcaption class="subtitle is-6">Figure 4: Summary of Certain Stimulation Techniques.</figcaption>
          </figure>
        </div>

	<!-- è½®æ’­é¡¹4 -->
        <div class="item">
          <figure class="image-container">
            <img src="figs/summary_verification.png" alt="TTS verification"/>
            <figcaption class="subtitle is-6">Figure 5:  Summary of Certain Verification Techniques.</figcaption>
          </figure>
        </div>

	<!-- è½®æ’­é¡¹4 -->
        <div class="item">
          <figure class="image-container">
            <img src="figs/summary_aggregation.png" alt="TTS aggregation"/>
            <figcaption class="subtitle is-6">Figure 6:  Summary of Certain Aggregation Techniques.</figcaption>
          </figure>
        </div>

	<!-- è½®æ’­é¡¹4 -->
        <div class="item">
          <figure class="image-container">
            <img src="figs/summary_benchmarks.png" alt="TTS benchmarks"/>
            <figcaption class="subtitle is-6">Figure 7:  Summary of Benchmarks</figcaption>
          </figure>
        </div>

	<!-- è½®æ’­é¡¹4 -->
        <div class="item">
          <figure class="image-container">
            <img src="figs/trend.png" alt="TTS trend"/>
            <figcaption class="subtitle is-6">Figure 8: From Emergence to the Next Frontier, the Evolutionary Path of Test-Time Scaling</figcaption>
          </figure>
        </div>

      </div>
    </div>
  </div>
</section>


<style>
  /* è½®æ’­å®¹å™¨ï¼šå®½åº¦+å±…ä¸­ */
.carousel {
  max-width: 600px;
  margin: 0 auto;
  display: flex;
  justify-content: center;
  align-items: center;
  flex-wrap: wrap;
}

/* figureå®¹å™¨ï¼šå›ºå®šé«˜300px + ç›¸å¯¹å®šä½ */
.image-container {
  position: relative;   /* å…³é”®ï¼šè®©figcaptionç»å¯¹å®šä½ */
  width: 100%;
  height: 300px;
  overflow: hidden;
  margin: 0;            /* å»æ‰é»˜è®¤figure margin */
}

/* å›¾ç‰‡ï¼šå®Œæ•´æ˜¾ç¤ºï¼Œä¸è£å‰ª */
.image-container img {
  display: block;       /* é¿å…å¤šä½™ç©ºç™½ */
  width: 100%;
  height: 100%;
  object-fit: contain;  /* ä¿æŒæ•´å›¾å¯è§ */
}

/* æ ‡é¢˜å åŠ åœ¨å›¾ç‰‡åº•éƒ¨ */
.image-container figcaption {
  position: absolute;
  bottom: 0;             /* è´´åº•éƒ¨ */
  left: 0;               /* å·¦å¯¹é½å®¹å™¨ */
  width: 100%;           /* å æ»¡å®¹å™¨å®½åº¦ */
  color: #fff;           /* ç™½è‰²æ–‡å­— */
  background-color: rgba(0,0,0,0.5); /* åŠé€æ˜èƒŒæ™¯ */
  text-align: center;
  padding: 0.5rem 1rem;  /* è®©æ ‡é¢˜æœ‰ç‚¹å†…è¾¹è· */
  margin: 0;             /* å»æ‰é»˜è®¤margin-top */
  box-sizing: border-box;
}
</style>
<!-- End image carousel -->

<section class="section" id="taxonomy">
  <div class="container is-max-desktop">
    <h2 class="title is-3">ğŸ§¬ Taxonomy</h2>
    
    <!-- 1. What to Scale -->
    <h3 class="title is-4">1. What to Scale</h3>
    <p>
      â€œWhat to scaleâ€ refers to the specific form of TTS that is expanded or adjusted to enhance an LLMâ€™s performance during inference.
    </p>
    <ul style="margin-bottom: 1.5rem;">
      <li><strong>Parallel Scaling:</strong> improves test-time performance by generating multiple outputs in parallel and then aggregating them into a final answer.</li>
      <li><strong>Sequential Scaling:</strong> involves explicitly directing later computations based on intermediate steps.</li>
      <li><strong>Hybrid Scaling:</strong> exploits the complementary benefits of parallel and sequential scaling.</li>
      <li><strong>Internal Scaling:</strong> elicits a model to autonomously determine how much computation to allocate for reasoning during testing within the modelâ€™s internal parameters, instead of external human-guided strategies.</li>
    </ul>

    <!-- 2. How to Scale -->
    <h3 class="title is-4">2. How to Scale</h3>
    <ul style="margin-bottom: 1.5rem;">
      <li>
        <strong>Tuning</strong>
        <ul>
          <li><em>Supervised Fine-Tuning (SFT):</em> by training on synthetic or distilled long CoT examples, SFT allows a model to imitate extended reasoning patterns.</li>
          <li><em>Reinforcement Learning (RL):</em> RL can guide a modelâ€™s policy to generate longer or more accurate solutions.</li>
        </ul>
      </li>
      <li>
        <strong>Inference</strong>
        <ul>
          <li><em>Stimulation (STI):</em> It basically stimulates the LLM to generate more and longer samples instead of generating individual samples directly.</li>
          <li><em>Verification (VER):</em> The verification process plays an important role in TTS, and can be adapted to: 
            <ul style="list-style-type: circle; margin-left: 1.5rem;">
              <li>Directly select the output sample among various ones (Parallel Scaling).</li>
              <li>Guide the stimulation process and determine when to stop (Sequential Scaling).</li>
              <li>Serve as the criteria in the search process.</li>
              <li>Determine what sample to aggregate and how to aggregate them (e.g., weights).</li>
            </ul>
          </li>
          <li><em>Search (SEA):</em> Search is a time-tested technique for retrieving relevant information from large databases, and it can also systematically explore the potential outputs of LLMs to improve complex reasoning tasks.</li>
          <li><em>Aggregation (AGG):</em> Aggregation techniques consolidate multiple solutions into a final decision to enhance the reliability and robustness of model predictions at test time.</li>
        </ul>
      </li>
    </ul>

    <!-- 3. Where to Scale -->
    <h3 class="title is-4">3. Where to Scale</h3>
    <ul style="margin-bottom: 1.5rem;">
      <li><strong>Reasoning:</strong> Math, Code, Science, Game &amp; Strategy, Medical, etc.</li>
      <li><strong>General-Purpose:</strong> Basics, Agents, Knowledge, Open-Ended, Multi-Modal, etc.</li>
    </ul>

    <!-- 4. How Well to Scale -->
    <h3 class="title is-4">4. How Well to Scale</h3>
    <ul style="margin-bottom: 1.5rem;">
      <li><strong>Performance:</strong> measures correctness and robustness of outputs.</li>
      <li><strong>Efficiency:</strong> captures the cost-benefit tradeoffs of TTS methods.</li>
      <li><strong>Controllability:</strong> assesses whether TTS methods adhere to resource or output constraints, such as compute budgets or output lengths.</li>
      <li><strong>Scalability:</strong> quantifies how well models improve with more test-time compute (e.g., tokens or steps).</li>
    </ul>
  </div>
</section>

<section class="section has-background-light">
  <div class="container">
    <!-- æ ‡é¢˜ -->
    <h2 class="title is-3 has-text-centered">ğŸ” Paper Tables</h2>

    <!-- å¯ä»¥ç”¨Bulmaçš„cardæˆ–boxåŒ…è£¹è¡¨æ ¼ï¼Œè®©å®ƒæ›´æœ‰å±‚æ¬¡æ„Ÿ -->
    <div class="card" style="margin-top: 1.5rem;">
      <header class="card-header">
        <p class="card-header-title">Test-time Scaling Paper Summary</p>
      </header>

      <div class="card-content">
        <div class="table-container">
          <table class="table is-striped is-hoverable is-fullwidth">
            <thead>
              <tr>
                <th style="width:300px">Method (PapersTitles)</th>
                <th>What</th>
                <th>How â†’</th>
                <th></th>
                <th></th>
                <th></th>
                <th></th>
                <th></th>
                <th>Where</th>
                <th>How Well</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td></td>
                <td></td>
                <td>SFT</td>
                <td>RL</td>
                <td>STI</td>
                <td>SEA</td>
                <td>VER</td>
                <td>AGG</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td>
                  <i><b>Scaling llm test-time compute optimally can be more effective than scaling model parameters.</b></i>
                  <a href="https://arxiv.org/abs/2408.03314" target="_blank">
                    <img src="https://img.shields.io/badge/arXiv-2408.03314-red" alt="arXiv Badge">
                  </a>
                </td>
                <td>Parallel,<br>Sequential</td>
                <td>âœ—</td>
                <td>âœ—</td>
                <td>âœ—</td>
                <td>Beam,<br>LookAhead</td>
                <td>Verifier</td>
                <td>(Weighted) Best-of-N,<br>Stepwise Aggregation</td>
                <td>Math</td>
                <td>Pass@1,<br>FLOPsMatched Evaluation</td>
              </tr>
              <tr>
		<td><i><b>Multi-agent verification: Scaling test-time compute with goal verifiers</b></i><br>., <a href="https://arxiv.org/abs/2502.20379" target="_blank"><img src="https://img.shields.io/badge/arXiv-2502.20379-red" alt="arXiv Badge"></a></td>
		<td>Parallel</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>Self-Repetition</td>
		<td>âœ—</td>
		<td>Multiple-Agent<br>Verifiers</td>
		<td>Best-of-N</td>
		<td>Math,<br>Code,<br>General</td>
		<td>BoN-MAV (Cons@k),<br>Pass@1</td>
		</tr>
		<tr>
		<td><i><b>Evolving Deeper LLM Thinking</b></i><br>,  <a href="https://arxiv.org/abs/2501.09891" target="_blank"><img src="https://img.shields.io/badge/arXiv-2501.09891-red" alt="arXiv Badge"></a></td>
		<td>Sequential</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>Self-Refine</td>
		<td>âœ—</td>
		<td>Functional</td>
		<td>âœ—</td>
		<td>Open-Ended</td>
		<td>Success Rate,<br>Token Cost</td>
		</tr>
		<tr>
		<td><i><b>Meta-reasoner: Dynamic guidance for optimized inference-time reasoning in large language models</b></i><br>, <a href="https://arxiv.org/abs/2502.19918" target="_blank"><img src="https://img.shields.io/badge/arXiv-2502.19918-red" alt="arXiv Badge"></a></td>
		<td>Sequential</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>CoT +<br>Self-Repetition</td>
		<td>âœ—</td>
		<td>Bandit</td>
		<td>âœ—</td>
		<td>Game,<br>Sci,<br>Math</td>
		<td>Accuracy,<br>Token Cost</td>
		</tr>
		<tr>
		<td><i><b>START: Self-taught reasoner with tools</b></i><br>, <a href="https://arxiv.org/abs/2503.04625" target="_blank"><img src="https://img.shields.io/badge/arXiv-2503.04625-red" alt="arXiv Badge"></a></td>
		<td>Parallel,<br>Sequential</td>
		<td>Rejection Sampling</td>
		<td>âœ—</td>
		<td>Hint-infer</td>
		<td>âœ—</td>
		<td>Tool</td>
		<td>âœ—</td>
		<td>Math,<br>Code</td>
		<td>Pass@1</td>
		</tr>
		<tr>
		<td><i><b>" Well, Keep Thinking": Enhancing LLM Reasoning with Adaptive Injection Decoding</b></i><br>,  <a href="https://arxiv.org/abs/2503.10167" target="_blank"><img src="https://img.shields.io/badge/arXiv-2503.10167-red" alt="arXiv Badge"></a></td>
		<td>Sequential</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>Adaptive Injection<br>Decoding</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>Math,<br>Logical,<br>Commonsense</td>
		<td>Accuracy</td>
		</tr>
		<tr>
		<td><i><b>Chain of draft: Thinking faster by writing less</b></i><br>, <a href="https://arxiv.org/abs/2502.18600" target="_blank"><img src="https://img.shields.io/badge/arXiv-2502.18600-red" alt="arXiv Badge"></a></td>
		<td>Sequential</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>Chain-of-Draft</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>Math,<br>Symbolic,<br>Commonsense</td>
		<td>Accuracy,<br>Latency,<br>Token Cost</td>
		</tr>
		<tr>
		<td><i><b>rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking</b></i><br>, <a href="https://arxiv.org/abs/2501.04519" target="_blank"><img src="https://img.shields.io/badge/arXiv-2501.04519-red" alt="arXiv Badge"></a></td>
		<td>Hybrid</td>
		<td>imitation</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>MCTS</td>
		<td>PRM</td>
		<td>âœ—</td>
		<td>Math</td>
		<td>Pass@1</td>
		</tr>
		<tr>
		<td><i><b>Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling</b></i><br>, <a href="https://arxiv.org/abs/2502.06703" target="_blank"><img src="https://img.shields.io/badge/arXiv-2502.06703-red" alt="arXiv Badge"></a></td>
		<td>Parallel,<br>Hybrid</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>DVTS,<br>Beam Search</td>
		<td>PRM</td>
		<td>Best-of-N</td>
		<td>Math</td>
		<td>Pass@1,<br>Pass@k,<br>Majority,<br>FLOPS</td>
		</tr>
		<tr>
		<td><i><b>Tree of thoughts: Deliberate problem solving with large language models</b></i><br>, <a href="https://arxiv.org/abs/2305.10601" target="_blank"><img src="https://img.shields.io/badge/arXiv-2305.10601-red" alt="arXiv Badge"></a></td>
		<td>Hybrid</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>Propose Prompt,<br>Self-Repetition</td>
		<td>Tree Search</td>
		<td>Self-Evaluate</td>
		<td>âœ—</td>
		<td>Game,<br>Open-Ended</td>
		<td>Success Rate,<br>LLM-as-a-Judge</td>
		</tr>
		<tr>
		<td><i><b>Mindstar: Enhancing math reasoning in pre-trained llms at inference time</b></i><br>, <a href="https://arxiv.org/abs/2405.16265" target="_blank"><img src="https://img.shields.io/badge/arXiv-2405.16265-red" alt="arXiv Badge"></a></td>
		<td>Hybrid</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>LevinTS</td>
		<td>PRM</td>
		<td>âœ—</td>
		<td>Math</td>
		<td>Accuracy,<br>Token Cost</td>
		</tr>
		<tr>
		<td><i><b>Inference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for LLM Problem-Solving</b></i><br>, <a href="https://arxiv.org/abs/2408.00724" target="_blank"><img src="https://img.shields.io/badge/arXiv-2408.00724-red" alt="arXiv Badge"></a></td>
		<td>Hybrid</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>Reward Balanced<br>Search</td>
		<td>RM</td>
		<td>âœ—</td>
		<td>Math</td>
		<td>Test Error Rate,<br>FLOPs</td>
		</tr>
		<tr>
		<td><i><b>Reasoning-as-Logic-Units: Scaling Test-Time Reasoning in Large Language Models Through Logic Unit Alignment</b></i><br>, <a href="https://arxiv.org/abs/2502.07803" target="_blank"><img src="https://img.shields.io/badge/arXiv-2502.07803-red" alt="arXiv Badge"></a></td>
		<td>Hybrid</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>Self-Refine</td>
		<td>Control Flow Graph</td>
		<td>Self-Evaluate</td>
		<td>Prompt Synthesis</td>
		<td>Math,<br>Code</td>
		<td>Pass@1</td>
		</tr>
		<tr>
		<td><i><b>PlanGEN: A Multi-Agent Framework for Generating Planning and Reasoning Trajectories for Complex Problem Solving</b></i><br>, <a href="https://arxiv.org/abs/2502.16111" target="_blank"><img src="https://img.shields.io/badge/arXiv-2502.16111-red" alt="arXiv Badge"></a></td>
		<td>Parallel,<br>Hybrid</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>MoA</td>
		<td>âœ—</td>
		<td>Verification Agent</td>
		<td>Selection Agent</td>
		<td>Math,<br>General,<br>Finance</td>
		<td>Accuracy,<br>F1 Score</td>
		</tr>
		<tr>
		<td><i><b>A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods</b></i><br>, <a href="https://arxiv.org/abs/2502.01618" target="_blank"><img src="https://img.shields.io/badge/arXiv-2502.01618-red" alt="arXiv Badge"></a></td>
		<td>Hybrid</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>Particle-based<br>Monte Carlo</td>
		<td>PRM + SSM</td>
		<td>Particle Filtering</td>
		<td>Math</td>
		<td>Pass@1,<br>Budget vs. Accuracy</td>
		</tr>
		<tr>
		<td><i><b>Archon: An Architecture Search Framework for Inference-Time Techniques</b></i><br>, <a href="https://arxiv.org/abs/2409.15254" target="_blank"><img src="https://img.shields.io/badge/arXiv-2409.15254-red" alt="arXiv Badge"></a></td>
		<td>Hybrid</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>MoA,<br>Self-Repetition</td>
		<td>âœ—</td>
		<td>Verification Agent,<br>Unit Testing (Ensemble)</td>
		<td>Fusion</td>
		<td>Math,<br>Code,<br>Open-Ended</td>
		<td>Pass@1,<br>Win Rate</td>
		</tr>
		<tr>
		<td><i><b>Wider or deeper? scaling llm inference-time compute with adaptive branching tree search</b></i><br>, <a href="https://arxiv.org/abs/2503.04412" target="_blank"><img src="https://img.shields.io/badge/arXiv-2503.04412-red" alt="arXiv Badge"></a></td>
		<td>Hybrid</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>Mixture-of-Model</td>
		<td>AB-MCTS-(M,A)</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>Code</td>
		<td>Pass@1,<br>RMSLE,<br>ROC-AUC</td>
		</tr>
		<tr>
		<td><i><b>Thinking llms: General instruction following with thought generation</b></i><br>, <a href="https://arxiv.org/abs/2410.10630" target="_blank"><img src="https://img.shields.io/badge/arXiv-2410.10630-red" alt="arXiv Badge"></a></td>
		<td>Internal,<br>Parallel</td>
		<td>âœ—</td>
		<td>DPO</td>
		<td>Think</td>
		<td>âœ—</td>
		<td>Judge Models</td>
		<td>âœ—</td>
		<td>Open-Ended</td>
		<td>Win Rate</td>
		</tr>
		<tr>
		<td><i><b>Self-Evolved Preference Optimization for Enhancing Mathematical Reasoning in Small Language Models</b></i><br>, <a href="https://arxiv.org/abs/2503.04813" target="_blank"><img src="https://img.shields.io/badge/arXiv-2503.04813-red" alt="arXiv Badge"></a></td>
		<td>Internal,<br>Hybrid</td>
		<td>âœ—</td>
		<td>DPO</td>
		<td>Diversity Generation</td>
		<td>MCTS</td>
		<td>Self-Reflect</td>
		<td>âœ—</td>
		<td>Math</td>
		<td>Pass@1</td>
		</tr>
		<tr>
		<td><i><b>MA-LoT: Multi-Agent Lean-based Long Chain-of-Thought Reasoning enhances Formal Theorem Proving</b></i><br>, <a href="https://arxiv.org/abs/2503.03205" target="_blank"><img src="https://img.shields.io/badge/arXiv-2503.03205-red" alt="arXiv Badge"></a></td>
		<td>Internal,<br>Sequential</td>
		<td>imitation</td>
		<td>âœ—</td>
		<td>MoA</td>
		<td>âœ—</td>
		<td>Tool</td>
		<td>âœ—</td>
		<td>Math</td>
		<td>Pass@k</td>
		</tr>
		<tr>
		<td><i><b>Offline Reinforcement Learning for LLM Multi-Step Reasoning</b></i><br>, <a href="https://arxiv.org/abs/2412.16145" target="_blank"><img src="https://img.shields.io/badge/arXiv-2412.16145-red" alt="arXiv Badge"></a></td>
		<td>Internal,<br>Sequential</td>
		<td>âœ—</td>
		<td>OREO</td>
		<td>âœ—</td>
		<td>Beam Search</td>
		<td>Value Function</td>
		<td>âœ—</td>
		<td>Math,<br>Agent</td>
		<td>Pass@1,<br>Success Rate</td>
		</tr>
		<tr>
		<td><i><b>DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</b></i><br>, <a href="https://arxiv.org/abs/2501.12948" target="_blank"><img src="https://img.shields.io/badge/arXiv-2501.12948-red" alt="arXiv Badge"></a></td>
		<td>Internal</td>
		<td>warmup,<br>GRPO,<br>Rule-Based</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>Math,<br>Code,<br>Sci</td>
		<td>Pass@1,<br>cons@64,<br>Percentile,<br>Elo Rating,<br>Win Rate</td>
		<td></td>
		</tr>
		<tr>
		<td><i><b>s1: Simple test-time scaling</b></i><br>, <a href="https://arxiv.org/abs/2501.19393" target="_blank"><img src="https://img.shields.io/badge/arXiv-2501.19393-red" alt="arXiv Badge"></a></td>
		<td>Internal</td>
		<td>distillation</td>
		<td>âœ—</td>
		<td>Budget Forcing</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>Math,<br>Sci</td>
		<td>Pass@1,<br>Control,<br>Scaling</td>
		</tr>
		<tr>
		<td><i><b>O1 Replication Journey: A Strategic Progress Report â€“ Part 1</b></i><br>, <a href="https://arxiv.org/abs/2410.18982" target="_blank"><img src="https://img.shields.io/badge/arXiv-2410.18982-red" alt="arXiv Badge"></a></td>
		<td>Internal</td>
		<td>imitation</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>Journey Learning</td>
		<td>PRM,<br>Critique</td>
		<td>Multi-Agents</td>
		<td>Math</td>
		<td>Accuracy</td>
		</tr>
		<tr>
		<td><i><b>From drafts to answers: Unlocking llm potential via aggregation fine-tuning</b></i><br>, <a href="https://arxiv.org/abs/2501.11877" target="_blank"><img src="https://img.shields.io/badge/arXiv-2501.11877-red" alt="arXiv Badge"></a></td>
		<td>Internal,<br>Parallel</td>
		<td>imitation</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>Fusion</td>
		<td>âœ—</td>
		<td>Math,<br>Open-Ended</td>
		<td>Win Rate</td>
		</tr>
		<tr>
		<td><i><b>Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Though</b></i><br>,  <a href="https://arxiv.org/abs/2501.04682" target="_blank"><img src="https://img.shields.io/badge/arXiv-2501.04682-red" alt="arXiv Badge"></a></td>
		<td>Internal,<br>Hybrid</td>
		<td>imitation,<br>meta-RL</td>
		<td>Think</td>
		<td>MCTS,<br>A*</td>
		<td>PRM</td>
		<td>âœ—</td>
		<td>Math,<br>Open-Ended</td>
		<td>Win Rate</td>
		<td></td>
		</tr>
		<tr>
		<td><i><b>ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates</b></i><br>, <a href="https://arxiv.org/abs/2502.06772" target="_blank"><img src="https://img.shields.io/badge/arXiv-2502.06772-red" alt="arXiv Badge"></a></td>
		<td>Internal,<br>Sequential</td>
		<td>âœ—</td>
		<td>PPO,<br>Trajectory</td>
		<td>Thought Template Retrieve</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>Math</td>
		<td>Pass@1</td>
		<td></td>
		</tr>
		<tr>
		<td><i><b>L1: Controlling how long a reasoning model thinks with reinforcement learning</b></i><br>, <a href="https://arxiv.org/abs/2503.04697" target="_blank"><img src="https://img.shields.io/badge/arXiv-2503.04697-red" alt="arXiv Badge"></a></td>
		<td>Internal</td>
		<td>âœ—</td>
		<td>GRPO,<br>Length-Penalty</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>âœ—</td>
		<td>Math</td>
		<td>Pass@1,<br>Length Error</td>
		</tr>

              <tr>
                <td><i><b>Marco-o1: Towards Open Reasoning Models for Open-Ended Solutions</b></i><br>
                  <a href="https://arxiv.org/abs/2411.14405" target="_blank">
                    <img src="https://img.shields.io/badge/arXiv-2411.14405-red" alt="arXiv Badge">
                  </a>
                </td>
                <td>Internal,<br>Hybrid</td>
                <td>distillation,<br>imitation</td>
                <td>âœ—</td>
                <td>Reflection Prompt</td>
                <td>MCTS</td>
                <td>Self-Critic</td>
                <td>âœ—</td>
                <td>Math</td>
                <td>Pass@1,<br>Pass@k</td>
              </tr>
            </tbody>
          </table>
        </div> <!-- end .table-container -->
      </div> <!-- end .card-content -->
    </div> <!-- end .card -->
  </div> <!-- end .container -->
</section>
<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video"> -->
            <!-- Youtube embed code here -->
            <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\ -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->


  <!-- ===================== HANDSâ€‘ON GUIDELINES (GitHub Issues) ===================== -->
  <section id="guidelines" class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Open Handsâ€‘on Guidelines / å¼€æ”¾æ‰‹å†Œ</h2>
      <p class="content has-text-centered" style="margin-bottom: 1.5rem;">
      We understand that an individual's strength is limited. I hope our survey provides an open
      and practical platform where everyone can share their experiences in TTS practice within
      the community we are building. These experiences are invaluable and will benefit everyone.
      If the guidelines you provide are valuable, we will include them in the PDF version of the paper.
      </p>
      <div class="has-text-centered">
        <a class="button is-primary is-rounded"
	   href="https://github.com/testtimescaling/testtimescaling.github.io/issues/new?labels=guideline"
	   target="_blank">
	  <span class="icon">
	    <i class="fab fa-github"></i>
	  </span>
	  <span>Submit your Guidelines</span>
	</a>
      </div>
      <!-- æ–°å¢ï¼šIssues åˆ—è¡¨æ˜¾ç¤ºåŒº -->
      <div id="issues-list" class="content has-text-left" style="margin-top: 1.5rem;">
        <!-- è¿™é‡Œå°†é€šè¿‡JSå¡«å……åˆ—è¡¨å†…å®¹ -->
      </div>
    </div>
  </section>

  

  <!-- ===================== COMMENTS (giscus) ===================== -->
  <section id="comments" class="section hero is-light">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Comments &amp; Discussion</h2>
      <div id="giscus_container"></div>
    </div>
  </section>

  <script src="https://giscus.app/client.js"
        data-repo="testtimescaling/testtimescaling.github.io"
        data-repo-id="R_kgDOOVw6fw"
        data-category="Q&A"
        data-category-id="DIC_kwDOOVw6f84CpnwE"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="preferred_color_scheme"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>
<!-- SELECTED TALKS -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">Talks</h2>
      <iframe width="450" height="235" src="https://player.bilibili.com/player.html?bvid=BV18QVbz7Eq4&high_quality=1&autoplay=0&danmaku=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
      <iframe width="450" height="235" src="https://www.youtube.com/embed/iE6_fC2mjlw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
    </div>
  </section>
  <!-- ===================== BIBTEX ===================== -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{zhang2025whathowwherewell,
      title={What, How, Where, and How Well? A Survey on Test-Time Scaling in Large Language Models}, 
      author={Qiyuan Zhang and Fuyuan Lyu and Zexu Sun and Lei Wang and Weixu Zhang and Zhihan Guo and Yufei Wang and Niklas Muennighoff and Irwin King and Xue Liu and Chen Ma},
      year={2025},
      eprint={2503.24235},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2503.24235}, 
}</code></pre>
    </div>
  </section>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>

<!-- å¦‚æœä¸éœ€è¦deferï¼Œå¯ä»¥æ”¹ä¸ºæ™®é€š<script> -->
<script defer src=".js/fontawesome.all.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/bulma-carousel@4.0.4/dist/js/bulma-carousel.min.js"></script>
<script src=".js/bulma-slider.min.js"></script>
<script src=".js/index.js"></script>

<!-- å…³é”®ï¼šåˆå§‹åŒ–Bulma Carouselï¼Œè®©è½®æ’­å›¾åŠ¨èµ·æ¥ -->

<script>
document.addEventListener('DOMContentLoaded', () => {
  bulmaCarousel.attach('#results-carousel', {
    slidesToShow: 1,
    slidesToScroll: 1,
    loop: true,
    autoplay: true,
    autoplaySpeed: 3000,
    infinite: true,
  });
});
</script>
<script>
  async function loadIssues() {
    // 1) æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ç”¨æˆ·åå’Œä»“åº“å
    const owner = 'testtimescaling';  
    const repo = 'testtimescaling.github.io';  
    const label = 'guideline';

    // 2) GitHub APIè¯·æ±‚URLï¼Œå¯æ ¹æ®éœ€è¦æ·»åŠ  state=open / per_page=10 ç­‰
    const url = `https://api.github.com/repos/${owner}/${repo}/issues?labels=${label}&state=open&per_page=10`;

    try {
      // 3) å‘èµ·è¯·æ±‚ï¼Œè·å–Issuesåˆ—è¡¨
      const res = await fetch(url);
      const issues = await res.json();

      // 4) æ‰¾åˆ°HTMLä¸­ä¸“é—¨æ”¾ç½®Issuesåˆ—è¡¨çš„å®¹å™¨
      const wrap = document.getElementById('issues-list');
      if (!Array.isArray(issues) || issues.length === 0) {
        // å¦‚æœæ²¡æœ‰ä»»ä½•Issueï¼Œå°±è‡ªè¡Œå†³å®šè¦ä¸è¦æ˜¾ç¤ºç©ºæç¤º
        // wrap.innerHTML = '<p>æš‚æ— è®¨è®º</p>';
        return;
      }

      // 5) ç”Ÿæˆä¸€ä¸ªulï¼Œé€ä¸ªæ˜¾ç¤ºIssueæ ‡é¢˜å’Œé“¾æ¥
      const ul = document.createElement('ul');
      issues.forEach(issue => {
        const li = document.createElement('li');
        li.innerHTML = `
          <a href="${issue.html_url}" target="_blank">${issue.title}</a>
          <span class="has-text-grey-light">#${issue.number} Â· by ${issue.user.login}</span>
        `;
        ul.appendChild(li);
      });
      // 6) æŠŠulæ’å…¥wrap
      wrap.appendChild(ul);

    } catch (err) {
      console.error('Load issues failed:', err);
      // è¿™é‡Œå¯ä»¥æ”¾ä¸€ä¸ªæç¤ºæˆ–å¿½ç•¥
    }
  }

  // ç­‰é¡µé¢åŠ è½½å®Œæˆåå†è°ƒç”¨
  document.addEventListener('DOMContentLoaded', loadIssues);
</script>

</body>
</html>
